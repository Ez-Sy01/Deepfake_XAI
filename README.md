# Deepfake Detection with Explainable AI (XAI)

This repository contains code implementations for applying Explainable AI (XAI) techniques to deepfake detection models.  
We use visualization methods like **Grad-CAM**, **LIME**, and **SHAP** to interpret model decisions.

## ğŸ“¦ Download Project
You can download the entire project as a ZIP file
-> https://huggingface.co/spaces/Ez-SY01/DF_SW_XAI/resolve/main/DeepSCAN_XAI.zip

## ğŸ“‚ Project Structure
```
â”œâ”€â”€ gradio
  â”œâ”€â”€ algorithms/ # Pretrained models or model algorithmss
    â”œâ”€â”€ FreqNet/ # XAI methods (e.g., GradCAM, LIME, SHAP)
    â”œâ”€â”€ FreqNet_CAM/ # saved Input Image 
    â”œâ”€â”€ Grad_FreqNet/ # main Deepfake algorithm
    â”œâ”€â”€ GradCAM/ # Grad-CAM main code
  â”œâ”€â”€ SW_GradCAM.py # Script to run GRADCAM
â”œâ”€ example_fake_image.png
â”œâ”€ example_real_image.jpg
â””â”€â”€ README.md
```
## ğŸ§  Supported XAI Methods

- [x] Grad-CAM  
- [ ] LIME  
- [ ] SHAP  
- [ ] Integrated Gradients (coming soon)

## ğŸš€ Quick Start

### 1. Clone the repository
```bash
git clone https://github.com/yourusername/deepfake-xai.git
cd deepfake-xai
```
### 2. Install dependencies
-> we do not provide requirements.txt

### 3. Run Grad-CAM by FreqNet
```
python SW_GradCAM.py
```
After running, the local and public links will remain active for one week.

## ğŸ“ Notes
The pretrained model used is based on FreqNet trained on OpenForensics.

All outputs are class-specific explanations (Real vs. Fake).

This is a research prototype â€” for educational and research use.
